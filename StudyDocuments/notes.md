# Notes for Cognitive Impairment topic

## 7/23/2015

**From NCI Systematic Review Team Call 7/23/2015**

```
From: Ayse Tezcan [mailto:aztezcan@ucdavis.edu] 
Sent: Wednesday, July 22, 2015 9:19 PM
To: Meghan A Soulsby
Cc: Joy Melnikow; Shauna Durbin; Alinea Noronha; Ganz Patricia M.D.; Benjamin Chan; Bandos, Hanna; Rivera, Donna (NIH/NCI) [F] (donna.rivera@nih.gov); Freedman, Andrew (NIH/NCI) [E]; Kristen E Greenlee
Subject: *Update attachment* NCI Systematic Review Team Call, 7/23 @1:00pm PST
```

A large portion of the current literature on cognitive impairment evaluations
of chemotherapy for breast  cancer consists of cross-sectional studies.  In
these studies chemotherapy has a small to moderate  impact on cognition in the
short run, when women who are undergoing or have just completed  chemotherapy
are compared at one point in time to women who have not had chemotherapy.
This  effect is not significant in some studies; its magnitude depends on
study design; and domains affected  varies by study: Jim - verbal ability and
visuospatial ability; Ono – attention, executive function, motor  function,
processing speed and short-term memory.


Short-term prospective studies (mostly few weeks – 6 months) show improvement
over time in  chemotherapy group compared with baseline measures. Studies vary
in selection of the comparison  group and include women with breast cancer not
treated with chemotherapy, women treated with  hormonal therapy, and a healthy
comparison group (without breast cancer).   

Given the current state of published articles and meta-analyses investigating
cognitive function following adjuvant chemotherapy in early stage breast
cancer setting, we propose the following criteria  for our systematic review:

1. Limit inclusion to longitudinal studies with >= 1 year follow-up that either:
    
    a.  Investigate change from baseline chemo group alone, or
    
    b.  Investigate change from baseline and compare the change to a control
    group:  with may be either women with breast cancer but no chemo or women
    without breast cancer

2. Examine the moderating effects of these variables: type of comparison group
( no breast cancer vs breast cancer without chemotherapy vs endocrine tx),
age, IQ, education,  and measures of mood/anxiety/depression/fatigue

3.  Consider outcomes by domain to allow comparisons of effect sizes by study
and to report summary mean effect size.

4. Examine the within and across study effect sizes of individual tests and
identify commonly used individual measures with larger effect sizes

5. Examine whether common individual measures based on neuropsychological
tests might  represent cognitive domains, which may enable the recommended use
of specific tests in future  studies to reduce the redundant testing?

### Questions to Ben:

My responses in **bold.**

* Wefel, Fan, Tager and Ahles have reported standardized scores.  

**Wefel looks like it has ideal reporting of data we could use: pre and post mean scores for each measure/instrument. Would be better if we could get pre-post $\beta$ for each measure. This is the target we want to transform the data from other studies into.**

* Tager, Jenkins and Ahles have not reported individual test scores for each time point.  

* Tager reported the standardized baseline (T0) scores  and F test (DF, F
value and p values) results for time and domain scores – but no actual scores
for T1 and

**There is an erratum and supplementary material document. Table 3 is only for the motor domain; it does not present $\beta$s for the other domains, let alone the individual measures. The time-by-chemotherapy interaction numbers in Table 4 only tell us if the slopes comparing non-CT and CT are different. It doesn't tell us what the pre-post change in the CT group is. We need a more complete Table 3.**

* Jenkins reported regression (R^2, R^2_adj, F, p, factors, beta, t, p) on
baseline (Table 3) and percentage  of each group showing reliable change for
each test at T2 and T3 (Table 4) - but no baseline scores.

**Really need to get T1 data. Not sure what to do with the $\beta$s in Table 3. They don't present a $\beta_{pre-post}$. Table 4 gives percentages and counts can be backed out of those numbers; but this doesn't give any sense of the magnitude of the decline/improvement.**

* Ahles reported domain scores adjusted for age, education and baseline score
(Table 3) – no individual  (single) test scores.

**Reference #9 might have more information on how the domain scores were calculated. I took a quick look into this reference and I can't see that I can easily back-out an algorithm to get the values from the individual measures from a domain score.**

1\. We are writing to Tager, Jenkins, and Ahles to request the unadjusted mean
scores from each  time point with the hope getting additional data. In the
event of we do not receive the  requested data, is it possible to use any of
these studies’ reported data  obtain comparable  effect sizes for changes over
time in either domains or individual tests?

* The Fan study  (largest study) only included only a comparison group of
women without breast cancer; all the other (smaller) included studies used
either a comparison group with breast cancer not receiving  chemotherapy, or
the no-chemo group with an additional, no-breast cancer comparison group.

2\. Can we consider pooling the difference of differences of studies using
differently defined  comparison groups?

**It's probably not a good idea to pool studies with differing control groups. While it can be done (numbers are numbers), the real question is whether it should. We can try to do a sensitivity check and assess how different the control groups across the studies are. If the look similar enough in terms of CogImp measures and/or other variables, then it might be reasonable to pool.**

3\. With whatever studies we are ultimately able to include(based on questions
1 and 2), will we  have sufficient sample size to investigate the moderating
effects ofthese variables: type of  comparison  group (healthy vs women with
breast cancer not receiving chemotherapy),  presence or absence of additional
endocrine treatment,  age, IQ, education,  mood/anxiety/depression/fatigue

**With only 4 studies, and possibly not pool-able, I would hesitate to do more than a simple pooled estimate of effect size. I need to take a closer look at the Ono meta-analysis. Since it's so recent, I'm thinking that the most we could probably do is to take there results and add on a study or two and see how that new information changes Ono's results.**

**Looks like Ono was able to use Jenkins. I need to see how they did that.**


**AYSE, you included Bender, Collins, and McDonald, in the zip file of studies you sent me. Was I supposed to take a look at those too? They didn't see relevent, but maybe I missed something.**


## 8/4/2015

**For NCI Cognitive Impairment Call - 8/4 @ 3:30pm PST**

```
From: Benjamin Chan 
Sent: Tuesday, August 04, 2015 1:44 PM
To: 'Meghan A Soulsby'; Joy Melnikow; Ayse Zubeyde Tezcan; Ganz Patricia M.D.; Alinea Noronha; Van Dyk, Kathleen (KVanDyk@mednet.ucla.edu)
Cc: Kristen E Greenlee
Subject: RE: NCI Cognitive Impairment Call - 8/4 @ 3:30pm PST
```

Some thoughts after finally getting around to reading the Ono meta-analysis. We can talk about these on the call, but wanted to get my thoughts down.

* Of the 8 studies we have included (Collins, Bender, Fan, McDonald, Wefel, Tager, Jenkins, and Ahles), Ono included only 4 (Collins, Bender, Wefel, and Jenkins)
* I had a note to myself to figure out how Ono was able to include Jenkins. Ono states "Calculated effect sizes for each neuropsychological measure are available on request". *We're going to want to request these calculated effect sizes.* 
* This also shifts the required data to be the effect size, and not group means/SDs. This makes things a little easier.
* Ayse said the McDonald data is usable as-is (Table 2; only two measure reported, CES-D and STAI-S). 
    * CES-D and STAI-S are not neurological tests
    * McDonald reports working memory data **look for where this data is reported**
* Assuming we can get the individual effect sizes from Ono, then we *only need to get data from Fan, Tager, and Ahles.* 
    * Fan reports median for the Trails A and B (Table 9). Not ideal, but can probably "shoehorn" these into an effect size.
    * Fan also reports % with cognitive dysfunction using HSCS (Table 8). We can't use this as-is. We'd need the HSCS scores or to make some assumptions about the "normal/borderline", "mild", and "moderate-severe" categories.
        * Patty knows the authors
    * Tager reports effect sizes for the motor domain (Table 3; the t-value is the effect size). We don't really need to request more data w.r.t. Table 3. This only gets us data for a prospective comparison, however.
        * Patty does not know the authors
    * We might still want to request data from Tager to get data for the other domains
    * Ahles reports domain score means/SDs across time and broken out by group (Table 3). We're going to want something that looks like Table 3, but for the individual neurological tests.
        * Patty knows the authors

**TO-DO for Ben**
Draft language for a hierarchy of data elements.
E.g., "if you cannot send us X, then we would like to have Y."
